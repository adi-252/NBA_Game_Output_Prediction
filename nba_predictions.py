# -*- coding: utf-8 -*-
"""NBA_Predictions.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1L-xLYRIsxNE3uQICMKt9TXhzLKg-RVj4
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd

from google.colab import drive
drive.mount('/content/drive')

df = pd.read_csv("/content/drive/My Drive/ColabNotebooks/nba_games.csv", index_col = 0)

df = df.sort_values("date")

# DF indexed in same order as date
df = df.reset_index(drop = True)

# Identical or excess columns removed
del df["mp.1"]
del df["mp_opp.1"]
del df["index_opp"]

# Add target = how team did in the next game
# using all other data values to predict target
def add_target(team):
  team["target"] = team["won"].shift(-1)
  return team

# DF split into one DF per team
df = df.groupby("team", group_keys = False).apply(add_target)


# Data processing
# giving null values in the target column
df["target"][pd.isnull(df["target"])] = 2

# convert boolean into int
df["target"] = df["target"].astype(int, errors = "ignore")

df["won"].value_counts()

df["target"].value_counts()

nulls = pd.isnull(df)

nulls = nulls.sum()

nulls = nulls[nulls > 0]

valid_columns = df.columns[~df.columns.isin(nulls.index)]

df = df[valid_columns].copy();

# %pip install scikit-learn

# Need to train a model on a small set of columns using feature selector
from sklearn.model_selection import TimeSeriesSplit

removed_columns = ["season", "date", "won", "target", "team", "team_opp"]

selected_columns = df.columns[~df.columns.isin(removed_columns)]

from sklearn.feature_selection import SequentialFeatureSelector
from sklearn.linear_model import RidgeClassifier

rr = RidgeClassifier(alpha = 1)
split = TimeSeriesSplit(n_splits = 3)
sfs = SequentialFeatureSelector(rr, n_features_to_select = 30, direction = "forward", cv = split)


from sklearn.preprocessing import MinMaxScaler

scaler = MinMaxScaler()
df[selected_columns] = scaler.fit_transform(df[selected_columns])

sfs.fit(df[selected_columns], df["target"])

predictors = list(selected_columns[sfs.get_support()])

def backtest(data, model, predictors, start = 2, step = 1):
  # list of dataFrames where each df has predictions for that szn
  all_predictions = []
  seasons = sorted(data["season"].unique())

  for i in range(start, len(seasons), step):
    season = seasons[i]

    train = data[data["season"] < season]
    test = data[data["season"] == season]

    model.fit(train[predictors], train["target"])

    preds = model.predict(test[predictors])
    preds = pd.Series(preds, index = test.index)

    combined = pd.concat([test["target"], preds], axis = 1)
    combined.columns = ["actual", "prediction"]

    all_predictions.append(combined)

  return pd.concat(all_predictions)

predictions = backtest(df, rr, predictors)

predictions

from sklearn.metrics import accuracy_score

accuracy_score(predictions["actual"], predictions["prediction"])

df.groupby("home").apply(lambda x: x[x["won"] == 1].shape[0]/x.shape[0])

"""Cross Validation: creating predictions across dataset without using the same data. Train the data on one part and then predict using the other data.

Ridge Classifier uses ridge regression to predict. Works best after scaling the data by subtracting the mean and dividing by std. dev. Completed by doing fit_transform() on selected columns.

SqFS is passed in the machine learning model that it trains using different sets of features. Forward ensures it starts with picking 0 features, pick the feature that is best then picks antoher feature till we go up to 30 features.

sfs can be fit after passing in selected columns along with the target column we are trying to predict. This will give us the 30 best columns/features.

backtest() will split the data up by szn and use past szns to predict future szns. start param = 2 since 2 seasons needed before we start making predictions.
"""

# selected columns plus some extra to compute rolling averages
df_rolling = df[list(selected_columns) + ["won", "team", "season"]]

df_rolling

def find_team_averages(team):
  rolling = team.rolling(10).mean()
  return rolling

# want to group by we have avg performance of previous games of the same team in the same season.
df_rolling = df_rolling.groupby(["team", "season"], group_keys = False).apply(find_team_averages)

df_rolling
# Beginning of szn the team has not had enough games so there will be null values

rolling_cols = [f"{col}_10" for col in df_rolling.columns]

df_rolling.columns = rolling_cols

df = pd.concat([df, df_rolling], axis = 1)

df

# Can't have missing values
df = df.dropna()

df

# Giving our model information about future games that we know in advance.

def shift_col(team, col_name):
  next_col = team[col_name].shift(-1)
  return next_col

def add_col(df, col_name):
  return df.groupby("team", group_keys = False).apply(lambda x: shift_col(x, col_name))

df["home_next"] = add_col(df, "home")
df["team_opp_next"] = add_col(df, "team_opp")
df["date_next"] = add_col(df, "date")

df = df.copy()

full  = df.merge(
    df[rolling_cols + ["team_opp_next", "date_next", "team"]],
    left_on = ["team", "date_next"],
    right_on = ["team_opp_next", "date_next"])

full[["team_x", "team_opp_next_x", "team_y", "team_opp_next_y", "date_next"]]

removed_columns = ["season", "date", "won", "target", "team", "team_opp"]

removed_columns = list(full.columns[full.dtypes == "object"]) + removed_columns

removed_columns

selected_columns = full.columns[~full.columns.isin(removed_columns)]

sfs.fit(full[selected_columns], full["target"])

predictors = list(selected_columns[sfs.get_support()])

predictors

predictions = backtest(full, rr, predictors)

accuracy_score(predictions["actual"] , predictions["prediction"])